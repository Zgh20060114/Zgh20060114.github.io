{"title":"yolov5","uid":"f0da541dcd6df6287dc7b7bcefa5bded","slug":"yolov5","date":"2023-12-16T12:04:59.000Z","updated":"2023-12-17T08:35:51.729Z","comments":true,"path":"api/articles/yolov5.json","keywords":null,"cover":[],"content":"<p><img src=\"/../images/image-20231216210026711.png\" alt=\"image-20231216210026711\"></p>\n<p><img src=\"/../images/image-20231216210245075.png\" alt=\"image-20231216210245075\"></p>\n<h4 id=\"IOU-—-交并比\"><a href=\"#IOU-—-交并比\" class=\"headerlink\" title=\"IOU —-交并比\"></a>IOU —-交并比</h4><p><img src=\"/../images/image-20231216210441830.png\" alt=\"image-20231216210441830\"></p>\n<p>Lou为1意味着预测边界框和地面真实边界框完全重叠。<br>您可以为LOU设置阈值，以确定对象检测是否有效。<br>假设您将LOU设置为0.5，在这种情况下。<br>·如果LOU≥为0.5，则将目标检测归类为真阳性(TP)。<br>如果LOU&lt;0.5，则为错误检测，并将其归类为假阳性(FP)。<br>当图像中存在地面真实且模型未能检测到目标时，分类。<br>作为假阴性(FN)。<br>真负片(TN)：TN是我们没有预测到物体的图像的每一部分。<br>度量对于目标检测没有用处，因此我们忽略TN。</p>\n<p><img src=\"/../images/image-20231216210636311.png\" alt=\"image-20231216210636311\"></p>\n<h4 id=\"AP-MAP\"><a href=\"#AP-MAP\" class=\"headerlink\" title=\"AP,MAP\"></a>AP,MAP</h4><p><img src=\"/../images/image-20231216210923498.png\" alt=\"image-20231216210923498\"></p>\n<p><img src=\"/../images/image-20231216211711468.png\" alt=\"image-20231216211711468\"></p>\n<p><img src=\"/../images/image-20231216211921852.png\" alt=\"image-20231216211921852\"></p>\n<p><img src=\"/../images/image-20231216204704657.png\" alt=\"image-20231216204704657\">   </p>\n<p><img src=\"/../images/image-20231216204353728.png\" alt=\"image-20231216204353728\"> </p>\n<h4 id=\"网络架构和组件\"><a href=\"#网络架构和组件\" class=\"headerlink\" title=\"网络架构和组件\"></a>网络架构和组件</h4><p>单阶段检测器：</p>\n<p><img src=\"/../images/image-20231216205751067.png\" alt=\"image-20231216205751067\"></p>\n<p>yolov5：（没有划出专门的颈部Neck）</p>\n<p><img src=\"/../images/image-20231216212300844.png\" alt=\"image-20231216212300844\"></p>\n<p>git clone <a href=\"https://github.moeyy.xyz/https://github.com/ultralytics/yolov5.git![image-20231217123703969](../images/image-20231217123703969.png)\">https://github.moeyy.xyz/https://github.com/ultralytics/yolov5.git![image-20231217123703969](../images/image-20231217123703969.png)</a></p>\n<ol>\n<li><code>nc: 80</code>：这个参数表示模型分类数量（number of classes），默认为 80，对应着 COCO 数据集。</li>\n<li><code>depth_multiple: 0.33</code>：这个参数表示模型深度相对于基础版本的倍数。在 YOLOv5 中，有 S、M、L 和 X 四个版本，其中 S 为基础版本，即 <code>depth_multiple: 1.0</code>，而 M、L 和 X 版本为在此基础上分别加深了一定的层数。而 <code>depth_multiple: 0.33</code> 表示在 S 版本的基础上，深度缩小了 3 倍，即变成了 <code>depth_multiple: 0.33</code> × 3 &#x3D; 0.99。</li>\n<li><code>width_multiple: 0.50</code>：这个参数表示模型通道宽度相对于基础版本的倍数。与 <code>depth_multiple</code> 类似，S 版本的 <code>width_multiple</code> 是 1.0，而 M、L 和 X 版本则在此基础上分别扩大了一定的倍数。</li>\n<li><code>anchors</code>：这是一个锚点数组，用于定义不同尺度下的 anchor boxes。YOLOv5 中使用了三个不同的尺度，每个尺度使用三个不同的 anchor boxes。这些锚点大小是相对于输入图像的，因此不同尺度下的大小会有所差别。</li>\n<li><code>backbone</code>：这一部分定义了模型的骨干网络（backbone），包括卷积层、批归一化层和激活函数等。YOLOv5 使用了 CSPDarknet53 这个网络作为基础骨干网络，并在此基础上进行改进。具体而言，YOLOv5 增加了空间注意力机制和SPP模块，以增强特征表达能力。</li>\n<li><code>head</code>：这一部分定义了模型的检测头（detection head），包括检测网络和分类网络。YOLOv5 中的检测网络采用了YOLOv3中的FPN结构，并在此基础上加入了PANet模块和SAM模块，以提高检测性能。</li>\n</ol>\n<p>序列数据的不同采样方法（随机采样和顺序分区）会导致隐状态初始化的差异，原因如下：</p>\n<ol>\n<li>随机采样： 在随机采样中，我们从序列数据中随机选择一个序列作为训练样本。这意味着每次训练时，我们都使用不同的序列作为输入。由于每个序列可能具有不同的上下文和语义信息，模型在每次训练时都需要重新适应不同的序列特征。因此，随机采样会导致隐状态的初始化与之前的训练批次存在一定差异。</li>\n<li>顺序分区： 在顺序分区中，我们按顺序依次读取序列数据进行训练。这意味着模型在每个训练批次中都会接收到相邻的序列数据。由于相邻的序列通常具有相似的上下文和语义信息，模型可以利用之前批次的隐藏状态来帮助理解当前批次的序列。因此，顺序分区会导致隐状态的初始化与之前的训练批次存在一定的相关性。</li>\n</ol>\n<p>不同的隐状态初始化差异可能会对模型的训练和预测产生影响。随机采样可以增加数据的多样性，帮助模型更好地适应不同的序列特征。然而，随机采样可能也会引入一些噪声，导致训练过程更加不稳定。顺序分区可以利用相邻序列之间的相关性，帮助模型更好地捕捉到序列的上下文信息。然而，顺序分区可能会限制模型对不同序列特征的适应能力。</p>\n<p>困惑度（perplexity）是自然语言处理中常用的一个评价指标，主要用于衡量语言模型的预测性能。困惑度越低，表示模型的预测能力越好。</p>\n<p>在自然语言处理中，我们通常使用语言模型来计算文本序列的概率。给定一个文本序列 $W&#x3D;w_1,w_2,…,w_n$，其概率可以表示为：</p>\n<p>$$<br>P(W)&#x3D;P(w_1)\\times P(w_2|w_1) \\times … \\times P(w_n|w_1,w_2,…,w_{n-1})<br>$$</p>\n<p>其中，$P(w_i|w_1,w_2,…,w_{i-1})$ 表示在已知前面 $i-1$ 个词的情况下，第 $i$ 个词的概率。语言模型的目标就是学习这种条件概率分布。在模型训练过程中，我们通常会使用最大似然估计法来估计模型参数。</p>\n<p>困惑度是一个数值指标，表示用当前语言模型对一个测试集进行预测时所得到的困惑程度。具体而言，如果测试集包含 $N$ 个词，我们可以计算出每个词的概率 $P(w_i)$，然后将这些概率求倒数并取对数，即：</p>\n<p>$$<br>\\log \\frac{1}{P(w_1)}+\\log \\frac{1}{P(w_2|w_1)}+…+\\log \\frac{1}{P(w_N|w_1,w_2,…,w_{N-1})}<br>$$</p>\n<p>然后，我们可以将上述结果除以测试集中的词数 $N$，得到平均困惑度。具体而言，平均困惑度的计算公式如下：</p>\n<p>$$<br>\\text{Perplexity}&#x3D;exp\\left(-\\frac{1}{N}\\sum_{i&#x3D;1}^{N}\\log P(w_i)\\right)<br>$$</p>\n<p>例如，如果我们有一个包含100个句子的测试集，其中总共包含1000个词，我们可以使用语言模型来预测每个词的概率，并计算出平均困惑度。假设我们的模型预测准确率较高，平均每个词的概率为0.9，则平均困惑度为：</p>\n<p>$$<br>exp\\left(-\\frac{1}{1000}\\sum_{i&#x3D;1}^{1000}\\log 0.9\\right) \\approx 2.15<br>$$</p>\n<p>这表示我们的模型对测试集中的文本序列进行预测时，每个词的平均困惑度为2.15。如果我们使用一个更好的语言模型，其困惑度可能会更低。</p>\n<p>用困惑度来评价模型确保了不同长度的序列具有可比性</p>\n","feature":true,"text":" IOU —-交并比 Lou为1意味着预测边界框和地面真实边界框完全重叠。您可以为LOU设置阈值，以确定对象检测是否有效。假设您将LOU设置为0.5，在这种情况...","permalink":"/post/yolov5","photos":[],"count_time":{"symbolsCount":"2.6k","symbolsTime":"2 mins."},"categories":[],"tags":[{"name":"yolo","slug":"yolo","count":1,"path":"api/tags/yolo.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#IOU-%E2%80%94-%E4%BA%A4%E5%B9%B6%E6%AF%94\"><span class=\"toc-text\">IOU —-交并比</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#AP-MAP\"><span class=\"toc-text\">AP,MAP</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E5%92%8C%E7%BB%84%E4%BB%B6\"><span class=\"toc-text\">网络架构和组件</span></a></li></ol>","author":{"name":"Zgh","slug":"blog-author","avatar":"","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{},"next_post":{"title":"deeplearning","uid":"2dd54cd4b432aa48fbfa03c6312b571a","slug":"deeplearning","date":"2023-12-16T02:57:26.000Z","updated":"2023-12-16T03:00:14.787Z","comments":true,"path":"api/articles/deeplearning.json","keywords":null,"cover":null,"text":"在 Pandas 中，.apply() 是用于对 DataFrame 或 Series 中的元素应用指定函数的方法。 对于 DataFrame，.apply()...","permalink":"/post/deeplearning","photos":[],"count_time":{"symbolsCount":529,"symbolsTime":"1 mins."},"categories":[],"tags":[],"author":{"name":"Zgh","slug":"blog-author","avatar":"","link":"/","description":"","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true}}